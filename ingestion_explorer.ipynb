{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dotenv_utils import FromFileConfigGenerator, load_config\n",
    "from src.defaults import DEFAULT_ENV_FILE\n",
    "from src.utils.gcs_utils import GCSClientGenerator, GCSConfig\n",
    "from src.model.answers_generation import OpenAIConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "\n",
    "def print_pydantic_model(obj: BaseModel):\n",
    "    print(json.dumps(obj.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_getter = FromFileConfigGenerator(DEFAULT_ENV_FILE)\n",
    "gcs_config: GCSConfig = load_config(GCSConfig, configs_getter.get_config)\n",
    "openai_config: OpenAIConfig = load_config(OpenAIConfig, configs_getter.get_config)\n",
    "\n",
    "\n",
    "client_generator = GCSClientGenerator(gcs_config)\n",
    "storage_client = client_generator.get_client()\n",
    "\n",
    "BUCKET_NAME = 'bucket-optimusprime'\n",
    "bucket = storage_client.get_bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "from src.model.files.gcs import GCSFile\n",
    "\n",
    "\n",
    "bucket_blobs = [GCSFile.from_blob(blob) for blob in bucket.list_blobs()]\n",
    "print(len(bucket_blobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_blobs = [GCSFile.from_blob(blob) for blob in bucket.list_blobs()\n",
    "                        if blob.content_type in [\"application/pdf\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n"
     ]
    }
   ],
   "source": [
    "print(len(bucket_blobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "openai_client = OpenAI(api_key=openai_config.OPENAI_API_KEY, organization=openai_config.OPENAI_ORG_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.db_manager import VectorStoreFilesDB\n",
    "from src.utils.drive_utils import DriveConfig, DriveCredentials, ServiceGenerator\n",
    "\n",
    "drive_config = load_config(DriveConfig, configs_getter.get_config)\n",
    "drive_creds = DriveCredentials(drive_config)\n",
    "drive_service_generator = ServiceGenerator(drive_creds)\n",
    "vs_files_db = VectorStoreFilesDB(drive_service_generator.get_sheet_service(),\n",
    "                                 \"1XAhPXBsAecJUiyI13l6qtiI-iuITA4XjyDI11BLmGDo\",\n",
    "                                 \"VectorStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.db_manager import VectorStoreFileInfo\n",
    "\n",
    "\n",
    "test_blob = bucket_blobs[6]\n",
    "file_name = test_blob.name.split('/')[-1]\n",
    "file_bytes = bucket.blob(test_blob.name).download_as_bytes()\n",
    "file_folder = \"/\".join(test_blob.id.split('/')[:-2])\n",
    "\n",
    "vs_file = openai_client.files.create(\n",
    "  file=(file_name + \".pdf\", file_bytes),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "vs_file_info = VectorStoreFileInfo(\n",
    "    id=vs_file.id,\n",
    "    source_id=file_name,\n",
    "    source=\"gcs\",\n",
    "    folder_id=file_folder,\n",
    "    last_modified=test_blob.updated\n",
    ")\n",
    "vs_files_db.write(vs_file_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bucket-optimusprime/datacore/1-Tkk0P8e4OHE2IgvqBaMvjPzfcvvYuNwbSnR42TBb3A/1734778836618332'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blob.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
